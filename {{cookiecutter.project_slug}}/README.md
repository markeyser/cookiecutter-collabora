# {{cookiecutter.project_name}}

{{cookiecutter.description}}

## Directory Structure

```plaintext
├── .devcontainer                  <- Directory for Visual Studio Code Dev Container configuration.
│   └── devcontainer.json          <- Configuration file for defining the development container.
├── .github                        <- Directory for GitHub-specific configuration and metadata.
│   ├── CODEOWNERS                 <- File to define code owners for the repository.
│   ├── CONTRIBUTING.md            <- Guidelines for contributing to the project.
│   └── pull_request_template.md.  <- Template for pull requests to standardize and improve PR quality.
├── .vscode                        <- Directory for Visual Studio Code-specific configuration files.
│   ├── cspell.json                <- Configuration file for the Code Spell Checker extension.
│   ├── dictionaries               <- Directory for custom dictionary files.
│   │   └── data-science-en.txt    <- Custom dictionary for data science terminology.
│   ├── extensions.json            <- Recommended extensions for the project.
│   └── settings.json              <- Workspace-specific settings for Visual Studio Code.
├── config                         <- Configuration files for the project.
├── data                           <- Data for the project, divided into different stages of data processing.
│   ├── raw                        <- Original, immutable data dump.
│   ├── external                   <- Data from third-party sources.
│   ├── interim                    <- Intermediate data, partially processed.
│   ├── processed                  <- Fully processed data, ready for analysis.
│   └── features                   <- Engineered features ready for model training.
├── docs                           <- Documentation for the project.
│   ├── api-reference.md           <- API reference documentation.
│   ├── explanation.md             <- Detailed explanations and conceptual documentation.
│   ├── how-to-guides.md           <- Step-by-step guides on performing common tasks.
│   ├── index.md                   <- The main documentation index page.
│   └── tutorials.md               <- Tutorials related to the project.
├── log                            <- Logs generated by the project.
├── models                         <- Machine learning models, scripts, and other related artifacts.
├── notebooks                      <- Jupyter notebooks for experiments, examples, or data analysis.
├── scripts                        <- Directory for project-specific scripts and utilities.
│   └── hooks                      <- Directory for custom git hooks and other automation scripts.
│       ├── branch-name-check.sh   <- Hook script for checking branch names.
│       ├── commit-msg-check.sh    <- Hook script for checking commit messages.
│       ├── filename-check.sh      <- Hook script for checking file names.
│       ├── generate_docs.sh       <- Script for generating documentation.
│       └── restricted-file-check.sh   <- Hook script for checking restricted files.
├── src                            <- Source code for the project.
│   └── {{cookiecutter.package_name}}  <- Main project module.
│       ├── __init__.py            <- Initializes the Python package.
│       ├── main.py                <- Entry point for the application.
│       ├── app.py                 <- Main application logic.
│       └── utils.py               <- Utility functions.
├── tests                          <- Directory for all project tests.
│   ├── integration                <- Integration tests.
│   └── spec                       <- Specification tests (unit tests).
├── .gitignore                     <- Specifies intentionally untracked files to ignore.
├── .pre-commit-config.yaml        <- Configuration for pre-commit hooks.
├── Dockerfile                     <- Dockerfile for containerizing the application.
├── Makefile                       <- Makefile with commands like `make data` or `make train`.
├── mkdocs.yml                     <- Configuration file for MkDocs, a static site generator for project documentation.
├── pyproject.toml                 <- Configuration file for Python projects which includes dependencies and package information.
├── README.md                      <- The top-level README for developers using this project.
└── .env                           <- Environment variables configuration file (not visible).
```

## Getting Started

Sure, here's an updated version of the "Prerequisites" section in your README.md file, written from a software developer's perspective:

### Prerequisites

- **Development Environment**:
  - Visual Studio Code (VS Code) desktop
  - AWS Cloud Code Editor
  - GitHub Codespaces
  - Any other cloud-powered development environment compatible with VS Code or VS Code Open Source

- **Python**:
  - Ensure Python is installed on your system. This project is compatible with Python 3.x.

### Installation

1. Create a new Conda environment by cloning the base environment:

    ```sh
    conda create --name {{cookiecutter.package_name}}_env --clone base
    ```

    This command creates a new Conda environment named
    `{{cookiecutter.package_name}}_env` by cloning the existing `base`
    environment, which includes a long list of Python packages needed
    for development.

    >Please ensure you use the `{{cookiecutter.package_name}}_env` virtual
    >environment name. The `.vscode/settings.json` file assumes that the
    >path to your virtual environment is
    >`/home/sagemaker-user/.conda/envs/{{cookiecutter.package_name}}_env`. If
    >your virtual environment path differs, please update the
    >`.vscode/settings.json` file accordingly.


1. **Activate the new Conda environment**

    ```sh
    conda activate {{cookiecutter.package_name}}_env
    ```
2. **Clone the repository**

    ```sh
    git clone git@git.nylcloud.com:CDSAi/fp-servicesage-model.git
    cd fp-servicesage-model
    ```

3. **Install Poetry using pip**

    ```sh
    pip install poetry
    ```

4. **Install all dependencies (including development dependencies) using
   Poetry**

    ```sh
    poetry install
    ```

    This command tells `poetry` to install the package and include both
    the main dependencies specified under `[tool.poetry.dependencies]`
    and the development dependencies specified under
    `[tool.poetry.dev-dependencies]` in the `pyproject.toml` file.

    > Notice we are using Conda to create and manage the Python virtual
    > environment, and we are using Poetry to handle package
    > installation and dependency management within that environment.

5. **Adding Extensions in VS Code**

   1. **Find Extensions View**: Open the Extensions view by clicking the
      Extensions icon in the Sidebar or by pressing `Ctrl+Shift+X`.

   2. **Install Extensions**: Click the cloud icon with a download arrow
      at the bottom left to install extensions. Alternatively, you can
      search for the required extensions listed in the
      `.vscode/extensions.json` file.

   3. **Select Extensions**: Install the extensions specified in your
      project's `.vscode/extensions.json` file. This ensures your
      development environment is set up with the necessary tools.

   4. **Confirm Installation**: After selecting the extensions, confirm
      the installation and wait for the process to complete.

6. **Create the `.env` file**

    ```sh
    touch .env
    ```

    This file will be used to store all configuration secrets. Add your secrets to this file following the format:

    ```
    SECRET_KEY=your_secret_key
    DATABASE_URL=your_database_url
    ```

7. **Updating CSpell Dictionary with Python Terms**

    Improve spell checking by adding Python library terms to CSpell:

    ```bash
    make cspell_dictionary
    ```

    This enriches CSpell's dictionary with terms from your project's
    Python libraries, reducing false positives on technical jargon.

8. **Set up your environment variables**

    Before contributing to the project, you need to set up your
    environment variables to access different AWS resources. Follow
    these steps:

    Update the `.env` file with your settings:

    Open the `.env` file in a text editor and add the necessary AWS
    credentials and configuration details.

    ```sh
    # Example content for .env file
    AWS_ACCESS_KEY_ID=your_access_key_id
    AWS_SECRET_ACCESS_KEY=your_secret_access_key
    AWS_DEFAULT_REGION=your_default_region
    ```

9.  **Set up Docker (if needed)**

    ```sh
    docker build -t rag-qa-system .
    ```

11. **Set up pre-commit hooks**

    To ensure code quality and consistency, we use pre-commit hooks for
    linting, formatting, generating documentation, and running tests.
    Follow these steps to set up pre-commit hooks:

    a. **Install the pre-commit hooks**

    ```sh
    pre-commit install
    ```

    This command sets up the pre-commit hooks defined in the
    `.pre-commit-config.yaml` file. The hooks will now run automatically
    on every commit.

    b. **Run all pre-commit hooks on all files**

    ```sh
    pre-commit run --all-files
    ```

    Expected output:

    ```plaintext
    run tests................................................................Passed
    black-formatter..........................................................Passed
    black-jupyter-formatter..................................................Passed
    ruff-linter..............................................................Passed
    mypy.....................................................................Passed
    trim trailing whitespace.................................................Passed
    fix end of files.........................................................Passed
    debug statements (python)................................................Passed
    detect private key.......................................................Passed
    check for added large files..............................................Passed
    prettier.................................................................Passed
    restricted file and section..............................................Passed
    filename snake case......................................................Passed
    generate documentation...................................................Passed
    ```

    In the output above, "Passed" indicates that each pre-commit hook has successfully run.

    By following these steps, you ensure that the codebase adheres to
    the project's coding standards and that any issues are caught early
    in the development process.

## Usage

### Running the Application

To run the main application, use:

```sh
python src/main.py
```

### Data Preprocessing

To preprocess data, use the script provided in the `scripts` directory:

```sh
python scripts/preprocess_data.py
```

### Model Deployment

To deploy the model on SageMaker:

```sh
python sagemaker/deploy_script.py
```

## Development

### Running Tests

To run all the tests, use the following
command

```sh
poetry run pytest
```

### Formatting, Linting & Type Checking

Use `black` for code formatting, `ruff` for linting, and `mypy` for type
checking:

```sh
poetry run black .
poetry run ruff check --preview --fix .
poetry run mypy .
```

To run all three commands for a single file:

```sh
poetry run black path/to/your/file.py
poetry run ruff check --preview --fix path/to/your/file.py
poetry run mypy path/to/your/file.py
```

Additionally, you can use `pre-commit` to run checks:

```sh
pre-commit run --all-files
pre-commit run --files path/to/your/file.py
```

⚠️ **Before pushing your changes to GitHub, ensure that all Python files
are formatted, linted, and type-checked.**

### Explanation

- **`poetry run black .`**: Formats your code to conform to the Black
  code style.
- **`poetry run ruff check --preview --fix .`**: Runs Ruff to check for
  linting issues and automatically fixes them.
- **`poetry run mypy .`**: Runs mypy to check for type errors in your
  code.
- **`poetry run black path/to/your/file.py`**: Formats the specified
  file to conform to the Black code style.
- **`poetry run ruff check --preview --fix path/to/your/file.py`**: Runs
  Ruff to check for linting issues in the specified file and
  automatically fixes them.
- **`poetry run mypy path/to/your/file.py`**: Runs mypy to check for
  type errors in the specified file.
- **`pre-commit run --all-files`**: Runs all configured `pre-commit`
  hooks on all files.
- **`pre-commit run --files path/to/your/file.py`**: Runs all configured
  `pre-commit` hooks on the specified file.

## Configuration

Configuration files are located in the `config` directory. Update these
files to suit your environment and requirements.

### Environment Variables

Environment variables are managed in the `.env` file. Update this file
with your specific settings.

## Contributing

We welcome contributions! Please read our
[CONTRIBUTING.md](.github/CONTRIBUTING.md) guide for more information on
how to contribute.

## Contact

For questions or comments, please open an issue on GitHub or contact the
project maintainers.
